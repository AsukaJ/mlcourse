#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass beamer
\begin_preamble
\usetheme{CambridgeUS} 
\beamertemplatenavigationsymbolsempty


% Set Color ==============================
\definecolor{NYUPurple}{RGB}{87,6,140}
\definecolor{LightPurple}{RGB}{165,11,255}


\setbeamercolor{title}{fg=NYUPurple}
%\setbeamercolor{frametitle}{fg=NYUPurple}
\setbeamercolor{frametitle}{fg=NYUPurple}

\setbeamercolor{background canvas}{fg=NYUPurple, bg=white}
\setbeamercolor{background}{fg=black, bg=NYUPurple}

\setbeamercolor{palette primary}{fg=black, bg=gray!30!white}
\setbeamercolor{palette secondary}{fg=black, bg=gray!20!white}
\setbeamercolor{palette tertiary}{fg=gray!20!white, bg=NYUPurple}

\setbeamertemplate{headline}{}

\setbeamercolor{parttitle}{fg=NYUPurple}
\setbeamercolor{sectiontitle}{fg=NYUPurple}
\setbeamercolor{sectionname}{fg=NYUPurple}
\setbeamercolor{section page}{fg=NYUPurple}

\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
\setbeamercolor{section title}{fg=NYUPurple}
 \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\usebeamercolor[fg]{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}
\end_preamble
\options aspectratio=169, handout
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "eulervm" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "allcolors=NYUPurple,urlcolor=LightPurple"
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 0
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\boxbgcolor #ff31d8
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\reals}{\mathbf{R}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\integers}{\mathbf{Z}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\naturals}{\mathbf{N}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\rationals}{\mathbf{Q}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\ca}{\mathcal{A}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cb}{\mathcal{B}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cc}{\mathcal{C}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cd}{\mathcal{D}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\ce}{\mathcal{E}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cf}{\mathcal{F}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cg}{\mathcal{G}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\ch}{\mathcal{H}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\ci}{\mathcal{I}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cj}{\mathcal{J}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\ck}{\mathcal{K}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cl}{\mathcal{L}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cm}{\mathcal{M}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cn}{\mathcal{N}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\co}{\mathcal{O}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cp}{\mathcal{P}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cq}{\mathcal{Q}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\calr}{\mathcal{R}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cs}{\mathcal{S}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\ct}{\mathcal{T}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cu}{\mathcal{U}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cv}{\mathcal{V}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cw}{\mathcal{W}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cx}{\mathcal{X}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cy}{\mathcal{Y}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cz}{\mathcal{Z}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\ind}[1]{1(#1)}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
pr}{P}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\renewcommand{\pr}{\mathbb{P}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\predsp}{\cy}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%{
\backslash
hat{
\backslash
cy}}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\renewcommand{\outsp}{\cy}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\prxy}{P_{\cx\times\cy}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\prx}{P_{\cx}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\prygivenx}{P_{\cy\mid\cx}}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
ex}{E}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\renewcommand{\ex}{\mathbb{E}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\var}{\textrm{Var}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\cov}{\textrm{Cov}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\sgn}{\textrm{sgn}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\sign}{\textrm{sign}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\kl}{\textrm{KL}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\law}{\mathcal{L}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\eps}{\varepsilon}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\as}{\textrm{ a.s.}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\io}{\textrm{ i.o.}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\ev}{\textrm{ ev.}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\convd}{\stackrel{d}{\to}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\eqd}{\stackrel{d}{=}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\del}{\nabla}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\loss}{\ell}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\risk}{R}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\emprisk}{\hat{R}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\lossfnl}{L}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\emplossfnl}{\hat{L}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\empminimizer}[1]{\hat{#1}^{*}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\minimizer}[1]{#1^{*}}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\optimizer}[1]{#1^{*}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\etal}{\textrm{et. al.}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\tr}{\operatorname{tr}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\trace}{\operatorname{trace}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\diag}{\text{diag}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\rank}{\text{rank}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\linspan}{\text{span}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\spn}{\text{span}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\proj}{\text{Proj}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\argmax}{\operatornamewithlimits{arg\, max}}
{\text{argmax}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\argmin}{\operatornamewithlimits{arg\, min}}
{\text{argmin}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\bfx}{\mathbf{x}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\bfy}{\mathbf{y}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\bfl}{\mathbf{\lambda}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\bfm}{\mathbf{\mu}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\calL}{\mathcal{L}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\vw}{\boldsymbol{w}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vx}{\boldsymbol{x}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vxi}{\boldsymbol{\xi}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\valpha}{\boldsymbol{\alpha}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vbeta}{\boldsymbol{\beta}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vsigma}{\boldsymbol{\sigma}}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\vtheta}{\boldsymbol{\theta}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vd}{\boldsymbol{d}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vs}{\boldsymbol{s}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vt}{\boldsymbol{t}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vh}{\boldsymbol{h}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\ve}{\boldsymbol{e}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vf}{\boldsymbol{f}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vg}{\boldsymbol{g}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vz}{\boldsymbol{z}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vk}{\boldsymbol{k}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\va}{\boldsymbol{a}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vb}{\boldsymbol{b}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vv}{\boldsymbol{v}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\vy}{\boldsymbol{y}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\dom}{\textrm{\textbf{dom} }}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\rank}{\text{\textbf{rank }}}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\conv}{\textrm{\textbf{conv} }}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\relint}{\text{\textbf{relint }}}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\aff}{\text{\textbf{aff }}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\hil}{\ch}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\rkhs}{\hil}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\ber}{\text{Ber}}
\end_inset


\end_layout

\begin_layout Part
Trees
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Contents
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\end_deeper
\begin_layout Section
Trees
\end_layout

\begin_layout Standard
\begin_inset Flex ArticleMode
status open

\begin_layout Plain Layout
Trees are our first truly nonlinear learning algorithm.
 We have certainly generated prediction functions that are nonlinear in
 inputs 
\begin_inset Formula $x\in\reals^{d}$
\end_inset

, but we did that by generating feature vectors that are nonlinear functions
 of 
\begin_inset Formula $x$
\end_inset

, and then we 
\series bold
learned
\series default
 the coefficients to linearly combine these nonlinear features.
 Trees are the first method that actually learn the nonlinearities.
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
A Binary Decision Tree
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_deeper
\begin_layout Standard
\align left

\series bold
binary tree
\series default
: each node has either 2 children or 0 children
\end_layout

\begin_layout Standard
\align left
\begin_inset Graphics
	filename ../Figures/trees/decisionTree.png
	lyxscale 50
	width 50theight%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From Criminisi et al.
 MSR-TR-2011-114, 28 October 2011.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Binary Decision Tree on 
\begin_inset Formula $\reals^{2}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Consider a binary tree on 
\begin_inset Formula $\left\{ \left(X_{1},X_{2}\right)\mid X_{1},X_{2}\in\reals\right\} $
\end_inset


\end_layout

\begin_layout Standard
\align left
\begin_inset Graphics
	filename ../Figures/trees/basicBinaryTree.png
	lyxscale 50
	width 50theight%

\end_inset


\begin_inset space \qquad{}
\end_inset


\begin_inset Graphics
	filename ../Figures/trees/binaryRegions.png
	lyxscale 50
	width 50theight%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From 
\backslash
emph{An Introduction to Statistical Learning, with applications in R} (Springer,
 2013) with permission from the authors: G.
 James, D.
 Witten,  T.
 Hastie and R.
 Tibshirani.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Types of Decision Trees
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
We'll only consider 
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
binary trees
\series default
 (vs multiway trees where nodes can have more than 2 children)
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
decisions at each node involve only a single feature (i.e.
 input coordinate)
\end_layout

\begin_layout Itemize
for continuous variables, splits always of the form 
\begin_inset Formula 
\[
x_{i}\le t
\]

\end_inset


\begin_inset Note Note
status open

\begin_layout Pause

\end_layout

\begin_layout Itemize
(Gives us a partition into convex polyhedral cells, each side parallel to
 a coordinate axis)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
for discrete variables, partitions values into two groups 
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Regression Trees
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Binary Regression Tree on 
\begin_inset Formula $\reals^{2}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Consider a binary tree on 
\begin_inset Formula $\left\{ \left(X_{1},X_{2}\right)\mid X_{1},X_{2}\in\reals\right\} $
\end_inset


\end_layout

\begin_layout Standard
\align left
\begin_inset Graphics
	filename ../Figures/trees/binaryRegions.png
	lyxscale 50
	width 50theight%

\end_inset


\begin_inset space \qquad{}
\end_inset


\begin_inset Graphics
	filename ../Figures/trees/binaryTree3D.png
	lyxscale 50
	width 50theight%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From 
\backslash
emph{An Introduction to Statistical Learning, with applications in R} (Springer,
 2013) with permission from the authors: G.
 James, D.
 Witten,  T.
 Hastie and R.
 Tibshirani.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Fitting a Regression Tree
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Given the partition 
\begin_inset Formula $\left\{ R_{1},\ldots,R_{M}\right\} $
\end_inset

, final prediction is
\begin_inset Formula 
\[
f(x)=\sum_{m=1}^{M}c_{m}\ind{x\in R_{m}}
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
How to choose 
\begin_inset Formula $c_{1},\ldots,c_{M}$
\end_inset

? 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
For loss function 
\begin_inset Formula $\ell(\hat{y},y)=\left(\hat{y}-y\right)^{2}$
\end_inset

, best is
\begin_inset Formula 
\[
\hat{c}_{m}=\text{ave}(y_{i}\mid x_{i}\in R_{m}).
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Trees and Overfitting
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
If we do enough splitting, every unique 
\begin_inset Formula $x$
\end_inset

 value will be in its own partition.
\end_layout

\begin_layout Itemize
This very likely overfits.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
As usual, we need to control the complexity of our hypothesis space.
\begin_inset Note Note
status open

\begin_layout Plain Layout
In Lecture 2, our tree complexity measure was 
\series bold
tree depth
\series default
.
\end_layout

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
CART (Breiman et al.
 1984) uses 
\series bold
number of terminal nodes
\series default
.
\end_layout

\begin_layout Itemize
Tree depth is also common.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Complexity of a Tree
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Let 
\begin_inset Formula $\left|T\right|=M$
\end_inset

 denote the number of terminal nodes in 
\begin_inset Formula $T$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
We will use 
\begin_inset Formula $\left|T\right|$
\end_inset

 to measure the complexity of a tree.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
For any given complexity, 
\end_layout

\begin_deeper
\begin_layout Itemize
we want the tree minimizing square error on training set.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Finding the optimal binary tree of a given complexity is computationally
 intractable.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Learning the simplest (smallest) decision tree is an NP-complete problem
 [Hyafil & Rivest ’76] 
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
We proceed with a 
\series bold
greedy algorithm
\end_layout

\begin_deeper
\begin_layout Itemize
Means build the tree one node at a time, without any planning ahead.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Root Node, Continuous Variables
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Let 
\begin_inset Formula $x=\left(x_{1},\ldots,x_{d}\right)\in\reals^{d}$
\end_inset

.
 (
\begin_inset Formula $d$
\end_inset

 features) 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Splitting variable
\series default
 
\begin_inset Formula $j\in\left\{ 1,\ldots,d\right\} $
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Split point
\series default
 
\begin_inset Formula $s\in\reals$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Partition based on 
\begin_inset Formula $j$
\end_inset

 and 
\begin_inset Formula $s$
\end_inset

:
\begin_inset Formula 
\begin{align*}
R_{1}(j,s) & =\left\{ x\mid x_{j}\le s\right\} \\
R_{2}(j,s) & =\left\{ x\mid x_{j}>s\right\} 
\end{align*}

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Root Node, Continuous Variables
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
For each splitting variable 
\begin_inset Formula $j$
\end_inset

 and split point 
\begin_inset Formula $s$
\end_inset

,
\begin_inset Formula 
\begin{eqnarray*}
\hat{c}_{1}(j,s) & = & \text{ave}(y_{i}\mid x_{i}\in R_{1}(j,s))\\
\hat{c}_{2}(j,s) & = & \text{ave}(y_{i}\mid x_{i}\in R_{2}(j,s))
\end{eqnarray*}

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Find 
\begin_inset Formula $j,s$
\end_inset

 minimizing loss
\begin_inset Formula 
\[
L(j,s)=\sum_{i:x_{i}\in R_{1}(j,s)}\left(y_{i}-\hat{c}_{1}(j,s)\right)^{2}+\sum_{i:x_{i}\in R_{2}(j,s)}\left(y_{i}-\hat{c}_{2}(j,s)\right)^{2}
\]

\end_inset


\end_layout

\begin_layout Itemize
How?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Finding the Split Point
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Consider splitting on the 
\begin_inset Formula $j$
\end_inset

'th feature 
\begin_inset Formula $x_{j}$
\end_inset

.
\begin_inset Note Note
status open

\begin_layout Pause

\end_layout

\begin_layout Itemize
As we change the split point 
\begin_inset Formula $s$
\end_inset

,
\end_layout

\begin_deeper
\begin_layout Itemize
the performance on training data changes at most 
\begin_inset Formula $n-1$
\end_inset

.
 
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
If 
\begin_inset Formula $x_{j(1)},\ldots,x_{j(n)}$
\end_inset

 are the sorted values of the 
\begin_inset Formula $j$
\end_inset

'th feature,
\end_layout

\begin_deeper
\begin_layout Itemize
we only need to check split points between adjacent values
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
traditionally take split points halfway between adjacent values:
\begin_inset Formula 
\[
s_{j}\in\left\{ \frac{1}{2}\left(x_{j(r)}+x_{j(r+1)}\right)\mid r=1,\ldots,n-1\right\} .
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
So only need to check performance of 
\begin_inset Formula $n-1$
\end_inset

 splits.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Then Proceed Recursively
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
We have determined 
\begin_inset Formula $R_{1}$
\end_inset

 and 
\begin_inset Formula $R_{2}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
Find best split for points in 
\begin_inset Formula $R_{1}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
Find best split for points in 
\begin_inset Formula $R_{2}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Enumerate
Continue...
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
When do we stop?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Complexity Control Strategy
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
If the tree is too big, we may overfit.
\end_layout

\begin_layout Itemize
If too small, we may miss patterns in the data (underfit).
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Can limit max depth of tree.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Can require all leaf nodes contain a minimum number of points.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Can require a node have at least a certain number of data points to split.
 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Can do 
\series bold
backward pruning
\series default
 – the approach of 
\series bold
CART
\series default
 (Breiman et al 1984): 
\end_layout

\begin_deeper
\begin_layout Enumerate
Build a really big tree (e.g.
 until all regions have 
\begin_inset Formula $\le5$
\end_inset

 points).
\end_layout

\begin_layout Enumerate

\series bold
\begin_inset Quotes eld
\end_inset

Prune
\begin_inset Quotes erd
\end_inset


\series default
 the tree back greedily all the way to the root, assessing performance on
 validation.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Classification Trees
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Classification Trees
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Consider classification case: 
\begin_inset Formula $\cy=\left\{ 1,2,\ldots,K\right\} $
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
We need to modify
\end_layout

\begin_deeper
\begin_layout Itemize
criteria for splitting nodes
\begin_inset Note Note
status open

\begin_layout Plain Layout
method for pruning tree 
\end_layout

\end_inset

 
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
What loss function to use for node splitting?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Natural loss function for classification is 
\begin_inset Formula $0/1$
\end_inset

 loss.
\end_layout

\begin_layout Itemize
Is this tractable for finding the best split?
\begin_inset Formula $\pause$
\end_inset

 Yes!
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Should we use it?
\begin_inset Formula $\pause$
\end_inset

 Maybe not! 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Other 
\begin_inset Quotes eld
\end_inset

node impurity measures
\begin_inset Quotes erd
\end_inset

 tend to work better: Gini index, entropy / deviance
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Details beyond our scope for today...
\end_layout

\end_deeper
\begin_layout Section
Trees in General
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Missing Features 
\begin_inset Note Note
status open

\begin_layout Plain Layout
(or 
\begin_inset Quotes eld
\end_inset

Predictors
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Itemize
Features are also called 
\series bold
covariates
\series default
 or 
\series bold
predictors
\series default
.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Itemize
What to do about missing features? 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
Throw out inputs with missing features
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Impute missing values with feature means
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
If a categorical feature, let 
\begin_inset Quotes eld
\end_inset

missing
\begin_inset Quotes erd
\end_inset

 be a new category.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
For trees we can do something else...
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Building a Tree when we have Missing Features
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Method suggested in the CART book (Breiman et al 1984):
\end_layout

\begin_layout Itemize
When we're finding the best split using a particular feature,
\end_layout

\begin_deeper
\begin_layout Itemize
we only use the examples that are not missing that feature.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Performance evaluation for the split is made only on the data available
 for that split.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Totally unclear how to evaluate in this case – what if we have very few
 examples with a particular feature, but it has a great impurity measure
 – is that good? 
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{I found the CART book a bit vague on this, so this is my best guess
 for what is intended.
 If somebody finds a clear statement, please let me know.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Surrogate Splits for Missing Data
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
For any non-terminal node that splits using feature 
\begin_inset Formula $f$
\end_inset

,
\end_layout

\begin_layout Itemize
we can find a 
\series bold
surrogate split 
\series default
using each of the other features.
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
To make a surrogate using 
\begin_inset Formula $f'$
\end_inset

, we find the split using 
\begin_inset Formula $f'$
\end_inset

 that best approximates the split using 
\begin_inset Formula $f$
\end_inset

\SpecialChar endofsentence

\end_layout

\begin_deeper
\begin_layout Itemize
Define 
\begin_inset Quotes eld
\end_inset

best
\begin_inset Quotes erd
\end_inset

 in term of 0/1 loss on the examples for which neither 
\begin_inset Formula $f$
\end_inset

 nor 
\begin_inset Formula $f'$
\end_inset

 is missing.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
If there are 
\begin_inset Formula $d$
\end_inset

 features, we'll have 
\begin_inset Formula $d-1$
\end_inset

 
\series bold
surrogate splits
\series default
 to approximate the split on 
\begin_inset Formula $f$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
We can rank these splits by how well they approximate the original split.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
We repeat the above process for every non-terminal node.
\end_layout

\begin_deeper
\begin_layout Itemize
So each node has the primary split and 
\begin_inset Formula $d-1$
\end_inset

 surrogate splits, where 
\begin_inset Formula $d$
\end_inset

 is the number of features.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
If we're predicting on an example and the feature needed to evaluate a split
 is missing,
\end_layout

\begin_deeper
\begin_layout Itemize
simply go down the list of surrogate splits until we get to one for which
 the feature is not missing.
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{I found the CART book a bit vague on this, so this is my best guess
 for what is intended.
 If somebody finds a clear statement, please let me know.}}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Categorical Features
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Suppose we have a categorical feature with 
\begin_inset Formula $q$
\end_inset

 possible values (unordered).
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
We want to find the best split into 2 groups
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
There are 
\begin_inset Formula $2^{q-1}-1$
\end_inset

 distinct splits.
 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Is this tractable? 
\begin_inset Formula $\pause$
\end_inset

 Maybe not in general.
 But...
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
For binary classification 
\begin_inset Formula $\cy=\left\{ 0,1\right\} $
\end_inset

, there is an efficient algorithm.
 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Some tree implementations (e.g.
 in R) use this for categorical features.
 But many (e.g.
 in sklearn) just use one-hot encoding for all categorical features and
 proceed as though the were numeric features.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Trees vs Linear Models
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Trees have to work much harder to capture linear relations.
\end_layout

\begin_layout Standard
\align left
\begin_inset Graphics
	filename ../Figures/trees/treeVsLinear.pdf
	lyxscale 30
	height 60theight%

\end_inset


\end_layout

\begin_layout Standard
\align left
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
let
\backslash
thefootnote
\backslash
relax
\backslash
footnotetext{
\backslash
tiny{From 
\backslash
emph{An Introduction to Statistical Learning, with applications in R} (Springer,
 2013) with permission from the authors: G.
 James, D.
 Witten,  T.
 Hastie and R.
 Tibshirani.}}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Interpretability
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Trees are certainly easy to explain.
\end_layout

\begin_layout Itemize
You can show a tree on a slide.
\end_layout

\begin_layout Itemize
Small trees seem interpretable.
\end_layout

\begin_layout Itemize
For large trees, maybe not so easy.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Trees for Nonlinear Feature Discovery
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Suppose tree 
\begin_inset Formula $T$
\end_inset

 gives partition 
\begin_inset Formula $R_{1},\ldots,R_{m}$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Predictions are
\begin_inset Formula 
\[
f(x)=\sum_{m=1}^{M}c_{m}\ind{x\in R_{m}}
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
Each region 
\begin_inset Formula $R_{m}$
\end_inset

 can be viewed as giving a feature function 
\begin_inset Formula $x\mapsto\ind{x\in R_{m}}$
\end_inset

.
\end_layout

\begin_layout Itemize
Can use these nonlinear features in e.g.
 lasso regression.
\begin_inset Note Note
status open

\begin_layout Plain Layout
This is called
\series bold
 rule fit 
\series default
by Friedman.
\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Pause

\end_layout

\begin_layout Itemize
Trees can be used to discover nonlinear features.
 
\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Instability / High Variance of Trees
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Trees are
\series bold
 high variance
\series default
: 
\end_layout

\begin_deeper
\begin_layout Itemize
If we randomly split the data, we may get quite different trees from each
 part 
\end_layout

\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
By contrast, linear models have low variance (at least when well-regularized)
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Later we investigate several ways to reduce this variance
\end_layout

\end_deeper
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Comments about Trees
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Trees make no use of 
\series bold
geometry
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\begin_layout Itemize
No inner products or distances
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize
called a 
\begin_inset Quotes eld
\end_inset

nonmetric
\begin_inset Quotes erd
\end_inset

 method
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Feature scale irrelevant
\series default
 
\end_layout

\begin_deeper
\begin_layout Pause

\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Prediction functions are not continuous
\end_layout

\begin_deeper
\begin_layout Itemize
not so bad for classification
\end_layout

\begin_layout Itemize
may not be desirable for regression
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\end_body
\end_document
